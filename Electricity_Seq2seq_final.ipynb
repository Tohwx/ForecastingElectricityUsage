{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72yk2BjRVs7q"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv07OpLiVs7r"
      },
      "source": [
        "This dataset [Electricity Load Diagrams 20112014 Data Set](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014#) is from UCI Machine Learning Repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q1JQuaLVs7s"
      },
      "source": [
        "### Data Set Information:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxmupfXnVs7s"
      },
      "source": [
        "Data set has no missing values.\n",
        "Values are in kW of each 15 min. To convert values in kWh values must be divided by 4.\n",
        "Each column represent one client. Some clients were created after 2011. In these cases consumption were considered zero.\n",
        "All time labels report to Portuguese hour. However all days present 96 measures (24*4). Every year in March time change day (which has only 23 hours) the values between 1:00 am and 2:00 am are zero for all points. Every year in October time change day (which has 25 hours) the values between 1:00 am and 2:00 am aggregate the consumption of two hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_Ky1ZC3NVs7p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSFfpj6uZh9y",
        "outputId": "1baad0fc-9cfd-4dcd-a579-daf278b3b576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  249M  100  249M    0     0  50.2M      0  0:00:04  0:00:04 --:--:-- 50.2M\n",
            "Archive:  LD2011_2014.txt.zip\n",
            "  inflating: LD2011_2014.txt         \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._LD2011_2014.txt  \n",
            "LD2011_2014.txt  LD2011_2014.txt.zip  __MACOSX\tsample_data\n"
          ]
        }
      ],
      "source": [
        "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip --output LD2011_2014.txt.zip\n",
        "!unzip LD2011_2014.txt.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JywkVrnoVs7s"
      },
      "outputs": [],
      "source": [
        "# url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00321/LD2011_2014.txt.zip'\n",
        "df = pd.read_csv(\"LD2011_2014.txt\", sep = ';', index_col = 0, dtype=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxSRrV7BVs7t",
        "outputId": "ed8e760f-bb85-4a12-fca3-cbe4c6bee72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(140256, 370)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyUA36piwQbq"
      },
      "source": [
        "# Data processing & Pre-Modeling\n",
        "\n",
        "TODO: FB Prophet, split subsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c87RrmfkmuUw"
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "- Melt the wide data matrix to long data matrix\n",
        "- Convert index to timestamps, entries to numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XEAcFI1Bmt69"
      },
      "outputs": [],
      "source": [
        "def preprocessing(dataframe):\n",
        "    # convert index (timestamp) to a new column\n",
        "    dataframe = dataframe.reset_index().rename(columns={\"index\": \"timestamp\"})\n",
        "\n",
        "    # unpivot the data\n",
        "    dataframe = dataframe.melt(id_vars=['timestamp'], var_name='user', value_name='usage_per_15min')\n",
        "    # fix the timestamp\n",
        "    dataframe['timestamp'] = pd.to_datetime(dataframe['timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
        "    # fix electricity usage\n",
        "    dataframe['usage_per_15min'] = dataframe['usage_per_15min'].apply(lambda x: str(x).replace(',', '.')).astype(float)\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "df = preprocessing(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "DhY6Qvizup4a",
        "outputId": "18f9171b-2484-4d77-d9d2-bea064e73052"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user</th>\n",
              "      <th>usage_per_15min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51894710</th>\n",
              "      <td>2014-12-31 21:45:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>8594.594595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51894711</th>\n",
              "      <td>2014-12-31 22:00:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>7891.891892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51894712</th>\n",
              "      <td>2014-12-31 22:15:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>7945.945946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51894713</th>\n",
              "      <td>2014-12-31 22:30:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>7351.351351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51894714</th>\n",
              "      <td>2014-12-31 22:45:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>7189.189189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51894715</th>\n",
              "      <td>2014-12-31 23:00:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>7621.621622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51894716</th>\n",
              "      <td>2014-12-31 23:15:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>6702.702703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51894717</th>\n",
              "      <td>2014-12-31 23:30:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>6864.864865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51894718</th>\n",
              "      <td>2014-12-31 23:45:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>6540.540541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51894719</th>\n",
              "      <td>2015-01-01 00:00:00</td>\n",
              "      <td>MT_370</td>\n",
              "      <td>7135.135135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   timestamp    user  usage_per_15min\n",
              "51894710 2014-12-31 21:45:00  MT_370      8594.594595\n",
              "51894711 2014-12-31 22:00:00  MT_370      7891.891892\n",
              "51894712 2014-12-31 22:15:00  MT_370      7945.945946\n",
              "51894713 2014-12-31 22:30:00  MT_370      7351.351351\n",
              "51894714 2014-12-31 22:45:00  MT_370      7189.189189\n",
              "51894715 2014-12-31 23:00:00  MT_370      7621.621622\n",
              "51894716 2014-12-31 23:15:00  MT_370      6702.702703\n",
              "51894717 2014-12-31 23:30:00  MT_370      6864.864865\n",
              "51894718 2014-12-31 23:45:00  MT_370      6540.540541\n",
              "51894719 2015-01-01 00:00:00  MT_370      7135.135135"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "J-Q1P59xdC4B",
        "outputId": "3c3c230f-21f4-43cd-d9eb-6074ab246d5e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>date</th>\n",
              "      <th>sum_per_day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MT_001</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MT_001</td>\n",
              "      <td>2011-01-02</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MT_001</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MT_001</td>\n",
              "      <td>2011-01-04</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MT_001</td>\n",
              "      <td>2011-01-05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     user       date  sum_per_day\n",
              "0  MT_001 2011-01-01          0.0\n",
              "1  MT_001 2011-01-02          0.0\n",
              "2  MT_001 2011-01-03          0.0\n",
              "3  MT_001 2011-01-04          0.0\n",
              "4  MT_001 2011-01-05          0.0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# aggregate the data to daily level\n",
        "def aggregate_date(dataframe):\n",
        "    dataframe['date'] = pd.to_datetime((dataframe.timestamp - np.timedelta64(1, 'm')).dt.date)\n",
        "    dataframe_day = dataframe.groupby(['user', 'date']).sum().reset_index()\n",
        "    dataframe_day = dataframe_day.rename(columns={'usage_per_15min': 'sum_per_day'})\n",
        "    #dataframe_day['std_per_day'] = dataframe.groupby(['user', 'date']).std().reset_index().usage_per_15min\n",
        "\n",
        "    return dataframe_day\n",
        "\n",
        "df_day = aggregate_date(df)\n",
        "df_day.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0JVf01mRvMN"
      },
      "source": [
        "## Create features\n",
        "\n",
        "ex. cyclic features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yVWeWiZgxsc9"
      },
      "outputs": [],
      "source": [
        "def feature_engineering_net(dataframe_raw):\n",
        "    dataframe = dataframe_raw.copy(deep=True)\n",
        "    dataframe.sort_values(by=[\"user\", \"date\"]).reset_index(drop=True, inplace=True)\n",
        "    dataframe['target'] = dataframe.groupby('user')['sum_per_day'].shift(-365)\n",
        "\n",
        "    dataframe['feat_year'] = dataframe['date'].dt.year\n",
        "    dataframe['feat_month'] = dataframe['date'].dt.month\n",
        "    dataframe['feat_day'] = dataframe['date'].dt.day\n",
        "    dataframe['feat_day_of_week'] = dataframe['date'].dt.dayofweek\n",
        "    #dataframe[[f'feat_{dow}' for dow in ['Mon', 'Tue', 'Wed', 'Thr', 'Fri', 'Sat', 'Sun']]] = pd.get_dummies(dataframe.day_of_week)\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "df_day_feat = feature_engineering_net(df_day)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU2qOKVlEAo6"
      },
      "source": [
        "$x_{\\sin }=\\sin \\left(\\frac{2 * \\pi * x}{\\max (x)}\\right)$\n",
        "\n",
        "$x_{\\cos }=\\cos \\left(\\frac{2 * \\pi * x}{\\max (x)}\\right)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Isp_Aaa2D-W1"
      },
      "outputs": [],
      "source": [
        "# Cyclic Transformation\n",
        "def cyclic_transformation(dataframe, features: list, drop=True):\n",
        "    dataframe = dataframe.copy(deep=True)\n",
        "    for feature in features:\n",
        "        dataframe[f'{feature}_sin'] = np.sin((2*np.pi*dataframe[feature])/(np.max(dataframe[feature])))\n",
        "        dataframe[f'{feature}_cos'] = np.cos((2*np.pi*dataframe[feature])/(np.max(dataframe[feature])))\n",
        "    \n",
        "    if drop:\n",
        "        dataframe = dataframe[[col for col in dataframe.columns if col not in features]]\n",
        "\n",
        "    return dataframe\n",
        "seasonal_feats = ['feat_month', 'feat_day', 'feat_day_of_week']\n",
        "\n",
        "df_day_feat = cyclic_transformation(df_day_feat, seasonal_feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nvx-Ylzybow5"
      },
      "outputs": [],
      "source": [
        "def format_tweak(dataframe):\n",
        "    '''\n",
        "    In Seq2seq model, we do not need to shift the target variable, therefore we make 'sum_per_day' as the target variable\n",
        "    Later we will use the resulting dataframe to create a custom PyTorch dataset\n",
        "    '''\n",
        "    dataframe = dataframe.copy(deep=True)\n",
        "    dataframe['user'] = dataframe['user'].str[3:].astype(int)\n",
        "    dataframe.drop(columns=['target'], inplace=True)\n",
        "    dataframe.rename(columns={'sum_per_day': 'target'}, inplace=True)\n",
        "    return dataframe\n",
        "\n",
        "df_day_feat = format_tweak(df_day_feat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "f9iJikIBbow5",
        "outputId": "f83a9f68-0a1f-476e-b518-ab72399be84f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>date</th>\n",
              "      <th>target</th>\n",
              "      <th>feat_year</th>\n",
              "      <th>feat_month_sin</th>\n",
              "      <th>feat_month_cos</th>\n",
              "      <th>feat_day_sin</th>\n",
              "      <th>feat_day_cos</th>\n",
              "      <th>feat_day_of_week_sin</th>\n",
              "      <th>feat_day_of_week_cos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.201299</td>\n",
              "      <td>0.979530</td>\n",
              "      <td>-8.660254e-01</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.394356</td>\n",
              "      <td>0.918958</td>\n",
              "      <td>-2.449294e-16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.571268</td>\n",
              "      <td>0.820763</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.724793</td>\n",
              "      <td>0.688967</td>\n",
              "      <td>8.660254e-01</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.866025</td>\n",
              "      <td>0.848644</td>\n",
              "      <td>0.528964</td>\n",
              "      <td>8.660254e-01</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user       date  target  feat_year  feat_month_sin  feat_month_cos  \\\n",
              "0     1 2011-01-01     0.0       2011             0.5        0.866025   \n",
              "1     1 2011-01-02     0.0       2011             0.5        0.866025   \n",
              "2     1 2011-01-03     0.0       2011             0.5        0.866025   \n",
              "3     1 2011-01-04     0.0       2011             0.5        0.866025   \n",
              "4     1 2011-01-05     0.0       2011             0.5        0.866025   \n",
              "\n",
              "   feat_day_sin  feat_day_cos  feat_day_of_week_sin  feat_day_of_week_cos  \n",
              "0      0.201299      0.979530         -8.660254e-01                   0.5  \n",
              "1      0.394356      0.918958         -2.449294e-16                   1.0  \n",
              "2      0.571268      0.820763          0.000000e+00                   1.0  \n",
              "3      0.724793      0.688967          8.660254e-01                   0.5  \n",
              "4      0.848644      0.528964          8.660254e-01                  -0.5  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_day_feat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fuR3wHWbow6",
        "outputId": "e485a222-360f-4f41-b03b-b1ec77d05e03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(540570, 10)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_day_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fzQLYgabow6",
        "outputId": "288c5e79-757a-4ccc-bd73-ec0a68443561"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "user\n",
              "1      1461\n",
              "252    1461\n",
              "251    1461\n",
              "250    1461\n",
              "249    1461\n",
              "       ... \n",
              "120    1461\n",
              "119    1461\n",
              "118    1461\n",
              "127    1461\n",
              "370    1461\n",
              "Length: 370, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_day_feat.groupby('user').size().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqI_9Qpcbow6"
      },
      "source": [
        "## Torch Dataset\n",
        "\n",
        "The following code is to create a torch dataset for the data. The torch dataset is a class that inherits from torch.utils.data.Dataset. It is used to create a dataset that can be used by the torch dataloader. The torch dataloader is used to create batches of data for training and testing.\n",
        "\n",
        "Each sample in the dataset is a dictionary with the following keys:\n",
        "\n",
        " - 'seq_feat': a tensor of shape (input_seq_len, num_seq_feat) containing the sequence features\n",
        " - 'cat_feat': a tensor of shape (input_seq_len, num_cat_feat) containing the categorical features (mostly user ids)\n",
        " - 'y': a tensor of shape (output_seq_len, 1) containing the target values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RMID-B1Ebow6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, df, seq_feat_cols, cat_feat_cols, y_col,\n",
        "                    embedding_sizes, seq_input_len, seq_output_len):\n",
        "\n",
        "        self.df = df.sort_values(['user', 'date'], ascending=True)\n",
        "        self.df = self.df.reset_index(drop=True)\n",
        "\n",
        "        #print(self.df.head())\n",
        "        self.seq_feat_cols = seq_feat_cols\n",
        "        self.cat_feat_cols = cat_feat_cols\n",
        "        self.y_col = y_col\n",
        "        self.embedding_sizes = embedding_sizes\n",
        "        self.seq_input_len = seq_input_len\n",
        "        self.seq_output_len = seq_output_len\n",
        "\n",
        "        self.num_users = self.df['user'].nunique()\n",
        "        self.seq_len_perUser = self.df.shape[0] // self.num_users #seq length per user\n",
        "\n",
        "        self.new_idx = []\n",
        "        for i in range(0, self.num_users):\n",
        "            seq_start_idx = self.seq_len_perUser * i\n",
        "            seq_end_idx = seq_start_idx + (self.seq_len_perUser - self.seq_input_len - self.seq_output_len + 1) - 1\n",
        "            \n",
        "            for j in range(seq_start_idx, seq_end_idx+1):\n",
        "                self.new_idx.append(j)\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        # each sample should be strictly sequential, assert(user.unique == 1)\n",
        "        \n",
        "        user_wise_len = self.df.shape[0]//self.num_users\n",
        "        user_wise_num_seq = user_wise_len - self.seq_input_len - self.seq_output_len + 1\n",
        "        #print(f\"model_seq_len_perUser: {user_wise_num_seq}\")\n",
        "        return user_wise_num_seq * self.num_users\n",
        "\n",
        "        #return self.df.shape[0] - self.seq_input_len - self.seq_output_len + 1 # 473426 for train, 201106 for test\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError\n",
        "        idx = len(self) + idx if idx < 0 else idx\n",
        "        if idx < 0:\n",
        "            raise IndexError\n",
        "\n",
        "        # split for each user 370 users\n",
        "        ## \n",
        "        ## for train: 272690 total, 737 per user\n",
        "        ##\n",
        "        #user_group = np.ceil((idx+1) / (len(self)/self.num_users)).astype(np.int16)\n",
        "        #print(f\"user group:{user_group})\")\n",
        "\n",
        "        idx = self.new_idx[idx]\n",
        "\n",
        "        seq_input_start_date = self.df.iloc[idx].date\n",
        "        seq_input_end_date = self.df.iloc[idx + self.seq_input_len - 1].date\n",
        "        seq_output_start_date = self.df.iloc[idx + self.seq_input_len].date\n",
        "        seq_output_end_date = self.df.iloc[idx + self.seq_input_len + self.seq_output_len - 1].date\n",
        "\n",
        "        # time series features\n",
        "        seq_feat = self.df.loc[idx:idx+self.seq_input_len-1, self.seq_feat_cols].values\n",
        "        seq_feat = torch.tensor(seq_feat, dtype=torch.float32)\n",
        "        # categorical features\n",
        "        cat_feat = self.df.loc[idx:idx+self.seq_input_len-1, self.cat_feat_cols].values\n",
        "        cat_feat = torch.tensor(cat_feat, dtype=torch.long)\n",
        "        # target\n",
        "        y = self.df.loc[idx+self.seq_input_len:idx+self.seq_input_len+self.seq_output_len-1, self.y_col].values\n",
        "        y = torch.tensor(y, dtype=torch.float32)\n",
        "        y = y.view(-1, 1)\n",
        "        \n",
        "        assert len(torch.unique(cat_feat)) == 1 # assert user is same for this sample sequence\n",
        "\n",
        "        return seq_feat, cat_feat, y#, self.embedding_sizes, seq_input_start_date, seq_input_end_date, seq_output_start_date, seq_output_end_date\n",
        "\n",
        "    def _get_test_item(self, idx):\n",
        "        if idx != 0:\n",
        "            raise IndexError\n",
        "        return self[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqrHmGDrbow7",
        "outputId": "d6c6a433-0463-4a09-a7cf-c5b3dbcb11da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "370"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_day_feat['user'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bydrhLXGbow7",
        "outputId": "0504debe-474c-4805-e394-29a2025c0f1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Timestamp('2011-01-01 00:00:00'), Timestamp('2014-12-31 00:00:00'))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_day_feat['date'].min(), df_day_feat['date'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTNOfON7xoa1",
        "outputId": "39b8c53c-7468-4bf3-ba69-2e83b8580ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_test_cutoff: 2013-12-31 00:00:00\n",
            "train_val_cutoff: 2013-11-01 00:00:00\n",
            "test_end_date: 2014-01-30 00:00:00\n",
            "train_df: (383320, 10)\n",
            "val_df: (44400, 10)\n",
            "test_df: (33300, 10)\n"
          ]
        }
      ],
      "source": [
        "# split the data\n",
        "IN_SEQ_LEN = 60 # 60 days as input\n",
        "OUT_SEQ_LEN = 30 # 30 days as output\n",
        "train_test_cutoff = df_day_feat['date'].max() - pd.Timedelta(days=365) # we will use last 365 days as test data\n",
        "train_val_cutoff = train_test_cutoff - pd.Timedelta(days=OUT_SEQ_LEN) - pd.Timedelta(days=30) #\n",
        "print(f\"train_test_cutoff: {train_test_cutoff}\")\n",
        "print(f\"train_val_cutoff: {train_val_cutoff}\")\n",
        "\n",
        "test_start_date = train_test_cutoff - pd.Timedelta(days=IN_SEQ_LEN)\n",
        "val_start_date = train_val_cutoff - pd.Timedelta(days=IN_SEQ_LEN)\n",
        "test_end_date = train_test_cutoff + pd.Timedelta(days=OUT_SEQ_LEN) # we only predict OUT_SEQ_LEN days in test, otherwise there will be duplicate y hat for each y and we will need to choose which one to use\n",
        "print(f\"test_end_date: {test_end_date}\")\n",
        "\n",
        "train_df = df_day_feat.query('date <= @train_val_cutoff').copy().reset_index(drop=True)\n",
        "val_df = df_day_feat.query('date > @val_start_date and date <= @train_test_cutoff').copy().reset_index(drop=True)\n",
        "test_df = df_day_feat.query('date > @test_start_date and date <= @test_end_date').copy().reset_index(drop=True)\n",
        "\n",
        "print(f\"train_df: {train_df.shape}\")\n",
        "print(f\"val_df: {val_df.shape}\")\n",
        "print(f\"test_df: {test_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi_QipkKxoa1",
        "outputId": "48a73b7e-5733-4f0e-8549-b83107679cf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['feat_year', 'feat_month_sin', 'feat_month_cos', 'feat_day_sin', 'feat_day_cos', 'feat_day_of_week_sin', 'feat_day_of_week_cos']\n",
            "Index(['user', 'date', 'target', 'feat_year', 'feat_month_sin',\n",
            "       'feat_month_cos', 'feat_day_sin', 'feat_day_cos',\n",
            "       'feat_day_of_week_sin', 'feat_day_of_week_cos'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "train_df.columns\n",
        "feature_cols = train_df.columns[train_df.columns.str.startswith('feat_')].tolist()\n",
        "print(feature_cols)\n",
        "print(train_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxmf0fFibow7",
        "outputId": "a3afdc9c-2d65-4e8f-a830-43c4dc6365bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 350390\n",
            "Val dataset size: 11470\n",
            "Test dataset size: 370\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "target_scaler = StandardScaler()\n",
        "feature_scaler = StandardScaler()\n",
        "\n",
        "train_df['target'] = target_scaler.fit_transform(train_df['target'].values.reshape(-1, 1))\n",
        "train_df[feature_cols] = feature_scaler.fit_transform(train_df[feature_cols])\n",
        "\n",
        "val_df['target'] = target_scaler.transform(val_df['target'].values.reshape(-1, 1))\n",
        "val_df[feature_cols] = feature_scaler.transform(val_df[feature_cols])\n",
        "\n",
        "test_df['target'] = target_scaler.transform(test_df['target'].values.reshape(-1, 1))\n",
        "test_df[feature_cols] = feature_scaler.transform(test_df[feature_cols])\n",
        "\n",
        "train_dataset = SequenceDataset(\n",
        "    df=train_df,\n",
        "    seq_feat_cols = ['target'] + list(df_day_feat.columns[df_day_feat.columns.str.startswith('feat_')]),\n",
        "    cat_feat_cols = ['user'],\n",
        "    y_col = 'target',\n",
        "    embedding_sizes = np.ceil(df_day_feat['user'].nunique() ** 0.5).astype(int),\n",
        "    seq_input_len = IN_SEQ_LEN,\n",
        "    seq_output_len = OUT_SEQ_LEN\n",
        ")\n",
        "\n",
        "val_dataset = SequenceDataset(\n",
        "    df=val_df,\n",
        "    seq_feat_cols = ['target'] + list(df_day_feat.columns[df_day_feat.columns.str.startswith('feat_')]),\n",
        "    cat_feat_cols = ['user'],\n",
        "    y_col = 'target',\n",
        "    embedding_sizes = np.ceil(df_day_feat['user'].nunique() ** 0.5).astype(int),\n",
        "    seq_input_len = IN_SEQ_LEN,\n",
        "    seq_output_len = OUT_SEQ_LEN\n",
        ")\n",
        "\n",
        "test_dataset = SequenceDataset(\n",
        "    df=test_df, \n",
        "    seq_feat_cols = ['target'] + list(df_day_feat.columns[df_day_feat.columns.str.startswith('feat_')]),\n",
        "    cat_feat_cols = ['user'],\n",
        "    y_col = 'target',\n",
        "    embedding_sizes = np.ceil(df_day_feat['user'].nunique() ** 0.5).astype(int),\n",
        "    seq_input_len = IN_SEQ_LEN,\n",
        "    seq_output_len = OUT_SEQ_LEN\n",
        ")\n",
        "\n",
        "print(f'Train dataset size: {len(train_dataset)}')\n",
        "print(f'Val dataset size: {len(val_dataset)}')\n",
        "print(f'Test dataset size: {len(test_dataset)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUZZDxsvbow8"
      },
      "source": [
        "### Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z429dexzbow8",
        "outputId": "44bdeca5-5a9f-43d6-8a39-902eeeacdff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1024, 60, 8]) torch.Size([1024, 60, 1]) torch.Size([1024, 30, 1])\n",
            "each batch dim: torch.Size([1024, 60, 8])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 1024 if torch.cuda.is_available() else 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "for seq_feat, cat_feat, y in train_loader:\n",
        "    print(seq_feat.shape, cat_feat.shape, y.shape)\n",
        "    break\n",
        "\n",
        "print(f\"each batch dim: {next(iter(train_loader))[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpuJPTElbow9"
      },
      "outputs": [],
      "source": [
        "# Seq2seq\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "class Seq2seqEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_seq_len = 365,\n",
        "                 feature_size = 1,\n",
        "                 hidden_size = 128,\n",
        "                 num_layers = 8,\n",
        "                 num_classes = 370,\n",
        "                 embed_size = 20,\n",
        "                 bidirectional = False,\n",
        "                 dropout_ratio = 0.2,\n",
        "                 decoder_hidden_size = 128,\n",
        "                 device = None):\n",
        "\n",
        "        super(Seq2seqEncoder, self).__init__()\n",
        "        self.input_seq_len = input_seq_len\n",
        "        self.feature_size = feature_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_classes = num_classes + 1\n",
        "        self.embed_size = embed_size\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.decoder_hidden_size = decoder_hidden_size\n",
        "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.embedding = nn.Embedding(self.num_classes, self.embed_size) # condition on sequence\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size = feature_size, # number of features\n",
        "            hidden_size = hidden_size,\n",
        "            num_layers = num_layers,\n",
        "            bidirectional = bidirectional,\n",
        "            dropout = dropout_ratio,\n",
        "            batch_first = True\n",
        "        )\n",
        "\n",
        "        \n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        \n",
        "        self.embed_to_hidden = nn.Linear(self.embed_size, self.hidden_size)\n",
        "        self.encHidden_to_decHidden = nn.Linear(self.hidden_size * self.num_directions, self.decoder_hidden_size)\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm1d(self.decoder_hidden_size)\n",
        "\n",
        "    def forward(self, data_loader_batch):\n",
        "        # data_loader_batch: (seq_len, batch_size, feature_size)\n",
        "        #print(f\"input shape: {data_loader_batch.shape}\")\n",
        "        seq_feat, cat_feat, y = data_loader_batch\n",
        "        seq_feat = seq_feat.to(self.device)\n",
        "        cat_feat = cat_feat.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "        batch_size = seq_feat.shape[0]\n",
        "        #print(f\"max cat_feat: {torch.max(cat_feat)}\")\n",
        "        #print(f\"min cat_feat: {torch.min(cat_feat)}\")\n",
        "        #print(f\"seq_feat shape: {seq_feat.shape}\")\n",
        "        #print(f\"cat_feat shape: {cat_feat.shape}\")\n",
        "        #print(f\"y shape: {y.shape}\")\n",
        "        #print(f\"cat_feat: {cat_feat}\")\n",
        "        #print(f\"y: {y}\")\n",
        "\n",
        "        # embed categorical features\n",
        "        # just use the first one\n",
        "        cat_feat = cat_feat[:, 0, :]\n",
        "        #print(f\"cat_feat shape: {cat_feat.shape}\")\n",
        "        cat_feat = cat_feat.view(-1)\n",
        "        #print(f\"cat_feat: {cat_feat}\")\n",
        "        #print(cat_feat.get_device())\n",
        "        embed_vector = self.embedding(cat_feat).requires_grad_(True)#.to(device)\n",
        "        #print(f\"ht shape: {ht.shape}\")\n",
        "        #print(f\"ht: {ht}\")\n",
        "        ht = self.embed_to_hidden(embed_vector)\n",
        "        #print(f\"ht shape: {ht.shape}\")\n",
        "        ht = ht.repeat(self.num_layers * self.num_directions, 1, 1)\n",
        "        #print(f\"ht shape: {ht.shape}\")\n",
        "\n",
        "        # pass through GRU\n",
        "        # output: (batch_size, seq_len, hidden_size * num_directions)\n",
        "        # hidden: (num_layers * num_directions, batch_size, hidden_size)\n",
        "        output, hidden = self.gru(seq_feat, ht)\n",
        "\n",
        "        #print(f\"output shape: {output.shape}\")\n",
        "        #print(f\"hidden shape: {hidden.shape}\")\n",
        "        if self.bidirectional:\n",
        "            # hidden = [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "            # hidden[-2, :, :] is the last of the forwards RNN\n",
        "            # hidden[-1, :, :] is the last of the backwards RNN\n",
        "\n",
        "            # output := [forward, backward]\n",
        "            # output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:]\n",
        "            #print(f\"output shape, after sum: {output.shape}\")\n",
        "            hidden = hidden.view(self.num_layers, 2, batch_size, self.hidden_size)\n",
        "            hidden = torch.cat((hidden[:, 0, :, :], hidden[:, 1, :, :]), dim = 1)\n",
        "            #print(f\"hidden shape, after cat: {hidden.shape}\")\n",
        "\n",
        "        else:\n",
        "            hidden = hidden[-1, :, :]\n",
        "            #print(f\"hidden shape, last: {hidden.shape}\")\n",
        "\n",
        "        # transform hidden state dim to match decoder hidden dim\n",
        "        hidden = self.encHidden_to_decHidden(hidden)\n",
        "        #hidden = self.batch_norm(hidden)\n",
        "        #print(f\"hidden shape, after transform: {hidden.shape}\")\n",
        "        return output, hidden, embed_vector\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    # arXiv:1409.0473\n",
        "    def __init__(self, encoder_hidden_size, decoder_hidden_size, bidirectional):\n",
        "        super(Attention, self).__init__()\n",
        "        self.encoder_hidden_size = encoder_hidden_size\n",
        "        self.decoder_hidden_size = decoder_hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        self.attn = nn.Linear(self.encoder_hidden_size * self.num_directions + self.decoder_hidden_size, decoder_hidden_size)\n",
        "        #print(self.attn)\n",
        "        self.v = nn.Linear(decoder_hidden_size, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs, bidirectional):\n",
        "        # hidden = [batch size, dec hid dim] (last input hidden state)\n",
        "        # encoder_outputs = [batch size, src len, enc hid dim * num directions]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[0]\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "\n",
        "        # repeat decoder hidden state src_len times\n",
        "        # hidden = [batch size, src len, dec hid dim]\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        #print(hidden.shape)\n",
        "        #print(encoder_outputs.shape)\n",
        "        #print(self.encoder_hidden_size * self.num_directions + self.decoder_hidden_size)\n",
        "        #print(torch.cat((hidden, encoder_outputs), dim=2).shape)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2))) # [batch size, src len, dec hid dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2) # [batch size, src len]\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Seq2seqDecoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_seq_len,\n",
        "                 feature_size,\n",
        "                 hidden_size = 128,\n",
        "                 num_layers = 8,\n",
        "                 num_classes = 370,\n",
        "                 embed_size = 20,\n",
        "                 output_seq_len = 365,\n",
        "                 bidirectional = False,\n",
        "                 dropout_ratio = 0.2,\n",
        "                 decoder_hidden_size = 128,\n",
        "                 encoder_hidden_size = 128,\n",
        "                 attention = None,\n",
        "                 use_attention = True):\n",
        "\n",
        "        super(Seq2seqDecoder, self).__init__()\n",
        "        self.input_seq_len = input_seq_len\n",
        "        self.feature_size = feature_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_classes = num_classes + 1\n",
        "        self.embed_size = embed_size\n",
        "        self.output_seq_len = output_seq_len\n",
        "        self.bidirectional = bidirectional\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.decoder_hidden_size = decoder_hidden_size\n",
        "        self.encoder_hidden_size = encoder_hidden_size\n",
        "        self.attention = attention\n",
        "        self.num_directions = 2 if self.bidirectional else 1\n",
        "        self.use_attention = use_attention\n",
        "        \n",
        "        self.repeat_label_times = int(np.ceil(self.encoder_hidden_size * self.num_directions / 2))\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size = self.encoder_hidden_size * self.num_directions + self.repeat_label_times + self.embed_size, #input_size = self.encoder_hidden_size * 4 if self.bidirectional else self.encoder_hidden_size * 2,\n",
        "            hidden_size = self.decoder_hidden_size,\n",
        "            num_layers = self.num_layers,\n",
        "            batch_first = True\n",
        "        )\n",
        "        \n",
        "        #self.fc_out = nn.Linear(self.decoder_hidden_size + self.encoder_hidden_size * self.num_directions + 1, 1)\n",
        "        self.fc_out = nn.Linear(self.decoder_hidden_size + self.encoder_hidden_size * self.num_directions, 1)\n",
        "\n",
        "        self.dropout = nn.Dropout(self.dropout_ratio)\n",
        "\n",
        "    def forward(self, dec_input, s, enc_output, embed_vector, attention=True):\n",
        "        # dec_input = [batch size]\n",
        "        # s = [batch size, dec hid dim] first time: hidden state of the encoder, after: previous hidden state of the decoder\n",
        "        # enc_output = [batch size, src len, enc hid dim * num directions]\n",
        "\n",
        "        # attention  a = [batch size, src len]\n",
        "        #print(f\"s shape {s.shape}\")\n",
        "        #print(f\"enc_output {enc_output.shape}\")\n",
        "        if attention:\n",
        "            a = self.attention(s, enc_output, self.bidirectional)\n",
        "            # [batch size, 1, src len]\n",
        "            a = a.unsqueeze(1)\n",
        "\n",
        "            c = torch.bmm(a, enc_output) # [batch size, 1, enc hid dim * num directions] # context vector\n",
        "        else:\n",
        "            # only preserve the hidden state from encoder or previous iter. decoder hidden state\n",
        "            c = s.unsqueeze(1) # [batch size, 1, dec hid dim]\n",
        "        # dec_input = [batch size, 1, 1]\n",
        "        dec_input = dec_input.unsqueeze(1).unsqueeze(2)\n",
        "        # dec_input = [batch size, 1, enc hid dim * num directions]\n",
        "        dec_input_repeat = dec_input.repeat(1, 1, self.repeat_label_times)\n",
        "\n",
        "        embed_vector = embed_vector.unsqueeze(1) # [batch size, 1, embed_size]\n",
        "\n",
        "        gru_input = torch.cat((dec_input_repeat, embed_vector, c), dim=2) # [batch size, 1, (enc hid dim * num directions) + num_repeat_label]\n",
        "        # hidden state of the decoder\n",
        "        s = s.repeat(self.num_layers, 1, 1)\n",
        "\n",
        "        # gru_output = [batch size, 1, dec hid dim], s = [n_layer, batch size, dec hid dim]\n",
        "        gru_output, s = self.gru(gru_input, s)\n",
        "        s = s[-1, :, :] # [batch size, dec hid dim] # last layer hidden state\n",
        "\n",
        "        c = c.squeeze(1) # [batch size, enc hid dim * num directions]\n",
        "        #dec_input = dec_input # [batch size, 1]\n",
        "        gru_output = gru_output.squeeze(1) # [batch size, dec hid dim]\n",
        "        # add dropout\n",
        "        gru_output = self.dropout(gru_output)\n",
        "        #prediction = self.fc_out(torch.cat((gru_output, c, dec_input.squeeze(2)), dim=1)) # [batch size, 1]\n",
        "        prediction = self.fc_out(torch.cat((gru_output, c), dim=1))\n",
        "        prediction = prediction.squeeze(1) # [batch size]\n",
        "        return prediction, s\n",
        "\n",
        "class Seq2seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder,\n",
        "                 decoder,\n",
        "                 device):\n",
        "        super(Seq2seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_batch, teacher_forcing_ratio = 0.5, inference = False):\n",
        "\n",
        "        # input_batch = input batch\n",
        "        # trg = [batch size, trg len] target time series\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "        inference = not self.training\n",
        "        batch_size = input_batch[0].shape[0]\n",
        "        src = input_batch[0][:, :, 0].to(self.device) # dim = [batch size, src len]\n",
        "        trg = input_batch[2][:, :, 0].to(self.device) # dim = [batch size, trg len]\n",
        "        trg_len = trg.shape[1]\n",
        "        # tensor to store decoder outputs\n",
        "        # [batch size, trg len]\n",
        "        outputs = torch.zeros(batch_size, trg_len).to(self.device)\n",
        "\n",
        "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        enc_output, s, embed_vector = self.encoder(input_batch)\n",
        "        # feed y(t-1) to the decoder\n",
        "        dec_input = src[:, -1] # [batch size]\n",
        "        #dec_input = torch.zeros(batch_size, 1).squeeze(1).to(self.device)\n",
        "\n",
        "        for t in range(0, trg_len):\n",
        "            # insert dec_input, previous hidden state and all encoder hidden states and outputs\n",
        "            # receive output tensor (predictions) and new hidden state\n",
        "            # dec_output = [batch size]\n",
        "            # s = [batch size, dec hid dim] last hidden state of the decoder\n",
        "            dec_output, s = self.decoder(dec_input, s, enc_output, embed_vector) \n",
        "            # outputs dim: [batch size, trg len]\n",
        "            #print(dec_output.shape)\n",
        "            #print(outputs[:, t].shape)\n",
        "            outputs[:, t] = dec_output\n",
        "\n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            teacher_force = False if inference else teacher_force\n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            dec_input = trg[:, t] if teacher_force else dec_output\n",
        "\n",
        "        return outputs\n",
        "        \n",
        "\n",
        "\n",
        "# test\n",
        "seq2seq_encoder_oneDirection = Seq2seqEncoder(\n",
        "    input_seq_len = 365,\n",
        "    feature_size = next(iter(train_loader))[0].shape[-1],\n",
        "    hidden_size = 128,\n",
        "    num_layers = 8,\n",
        "    num_classes = 370,\n",
        "    embed_size = 20,\n",
        "    bidirectional = False,\n",
        "    dropout_ratio = 0.2\n",
        ")\n",
        "seq2seq_encoder_twoDirection = Seq2seqEncoder(\n",
        "    input_seq_len = 365,\n",
        "    feature_size = next(iter(train_loader))[0].shape[-1],\n",
        "    hidden_size = 128,\n",
        "    num_layers = 8,\n",
        "    num_classes = 370,\n",
        "    embed_size = 20,\n",
        "    bidirectional = True,\n",
        "    dropout_ratio = 0.2\n",
        ")\n",
        "\n",
        "#seq2seq_encoder_oneDirection(next(iter(train_loader)))\n",
        "#seq2seq_encoder_twoDirection(next(iter(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf99DH4tBmBY",
        "outputId": "d733d0d9-650b-4b78-cc71-0c733313dd28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdjnhSbzbow9",
        "outputId": "a0c48a74-6774-48f0-cc32-0b1d04090d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# test\n",
        "ENCODER_HIDDEN_SIZE = 128\n",
        "DECODER_HIDDEN_SIZE = 128\n",
        "EMBED_SIZE = 20\n",
        "ENCODER_NUM_LAYERS = 4 #for 180 6\n",
        "DECODER_NUM_LAYERS = 2\n",
        "ENCODER_BIDIRECTIONAL = False\n",
        "\n",
        "encoder_test = Seq2seqEncoder(\n",
        "    input_seq_len = IN_SEQ_LEN,\n",
        "    feature_size = next(iter(train_loader))[0].shape[-1],\n",
        "    hidden_size = ENCODER_HIDDEN_SIZE,\n",
        "    num_layers = ENCODER_NUM_LAYERS,\n",
        "    num_classes = 370,\n",
        "    embed_size = EMBED_SIZE,\n",
        "    bidirectional = ENCODER_BIDIRECTIONAL,\n",
        "    dropout_ratio = 0.3,\n",
        "    decoder_hidden_size = DECODER_HIDDEN_SIZE\n",
        ").cuda()\n",
        "attention_test = Attention(encoder_hidden_size = ENCODER_HIDDEN_SIZE, decoder_hidden_size = DECODER_HIDDEN_SIZE, bidirectional = ENCODER_BIDIRECTIONAL).cuda()\n",
        "decoder_test = Seq2seqDecoder(\n",
        "    input_seq_len = IN_SEQ_LEN,\n",
        "    feature_size = next(iter(train_loader))[0].shape[-1],\n",
        "    hidden_size = ENCODER_HIDDEN_SIZE,\n",
        "    num_layers = DECODER_NUM_LAYERS,\n",
        "    num_classes = 370,\n",
        "    embed_size = EMBED_SIZE,\n",
        "    output_seq_len = OUT_SEQ_LEN,\n",
        "    bidirectional = ENCODER_BIDIRECTIONAL,\n",
        "    dropout_ratio = 0.3,\n",
        "    decoder_hidden_size = DECODER_HIDDEN_SIZE,\n",
        "    encoder_hidden_size = ENCODER_HIDDEN_SIZE,\n",
        "    attention = attention_test).cuda()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "#device = torch.device('mps')\n",
        "seq2seq_test = Seq2seq(encoder_test, decoder_test, device).cuda()\n",
        "#seq2seq_test(next(iter(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEyC9d4-VjT1",
        "outputId": "a5e7bf93-af3f-4b50-81b7-1100683ba67f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0191, -0.0270, -0.0016,  ..., -0.0033,  0.0115, -0.0098],\n",
              "        [-0.0741, -0.0778, -0.0839,  ..., -0.1033, -0.0893, -0.0632],\n",
              "        [-0.0665, -0.0482, -0.0760,  ..., -0.0630, -0.0568, -0.0585],\n",
              "        ...,\n",
              "        [-0.0547, -0.0279, -0.0231,  ..., -0.0169, -0.0003, -0.0339],\n",
              "        [-0.0549, -0.0224, -0.0258,  ..., -0.0566,  0.0086, -0.0263],\n",
              "        [-0.0391,  0.0101, -0.0182,  ...,  0.0347,  0.0258,  0.0507]],\n",
              "       device='cuda:0', grad_fn=<CopySlices>)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq2seq_test(next(iter(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2QBuKxsMV36"
      },
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self,yhat,y):\n",
        "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLeqbS6FgRDI"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "import datetime\n",
        "#!pip install torchmetrics --quiet\n",
        "#import torchmetrics\n",
        "from torch import optim\n",
        "import tqdm\n",
        "N_EPOCHS = 20\n",
        "#CRITERION = torchmetrics.MeanAbsolutePercentageError().cuda()\n",
        "CRITERION = RMSELoss().cuda()\n",
        "CRITERION = nn.MSELoss()\n",
        "def train(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    with tqdm.tqdm(total=len(iterator)) as pbar:\n",
        "        for i, batch in enumerate(iterator):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch)\n",
        "            real_target = batch[2][:, :, 0].to(device)\n",
        "            loss = criterion(output, real_target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_postfix(loss=loss.item())\n",
        "            pbar.update(1)\n",
        "    \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        with tqdm.tqdm(total=len(iterator)) as pbar:\n",
        "            for i, batch in enumerate(iterator):\n",
        "                output = model(batch, inference = True)\n",
        "                real_target = batch[2][:, :, 0].to(device)\n",
        "                loss = criterion(output, real_target)\n",
        "                epoch_loss += loss.item()\n",
        "                pbar.set_postfix(loss=loss.item())\n",
        "                pbar.update(1)\n",
        "    \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def train_model(model, train_iterator, valid_iterator, criterion, n_epochs):\n",
        "    best_valid_loss = float('inf')\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = train(model, train_iterator, criterion)\n",
        "        valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), f\"./gdrive/MyDrive/project-ML/full-length-seq2seq-{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}.pt\")\n",
        "        print(f'Epoch: {epoch+1:02}')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "    return train_losses, valid_losses\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpdGyMLHuk1T",
        "outputId": "6ea1096e-2fd4-48c4-da73-5ccc392622c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:11<00:00,  2.13s/it, loss=0.0093]\n",
            "100%|| 12/12 [00:23<00:00,  1.92s/it, loss=0.302]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.136\n",
            "\t Val. Loss: 0.047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:09<00:00,  2.13s/it, loss=0.0251]\n",
            "100%|| 12/12 [00:23<00:00,  1.92s/it, loss=0.304]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02\n",
            "\tTrain Loss: 0.043\n",
            "\t Val. Loss: 0.034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:07<00:00,  2.12s/it, loss=0.00413]\n",
            "100%|| 12/12 [00:22<00:00,  1.91s/it, loss=0.281]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 03\n",
            "\tTrain Loss: 0.033\n",
            "\t Val. Loss: 0.031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:06<00:00,  2.12s/it, loss=0.00507]\n",
            "100%|| 12/12 [00:23<00:00,  1.92s/it, loss=0.241]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 04\n",
            "\tTrain Loss: 0.026\n",
            "\t Val. Loss: 0.027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:05<00:00,  2.12s/it, loss=0.00291]\n",
            "100%|| 12/12 [00:23<00:00,  1.92s/it, loss=0.26]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 05\n",
            "\tTrain Loss: 0.023\n",
            "\t Val. Loss: 0.033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:05<00:00,  2.12s/it, loss=0.00283]\n",
            "100%|| 12/12 [00:23<00:00,  1.92s/it, loss=0.242]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 06\n",
            "\tTrain Loss: 0.020\n",
            "\t Val. Loss: 0.030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:04<00:00,  2.11s/it, loss=0.0163]\n",
            "100%|| 12/12 [00:22<00:00,  1.92s/it, loss=0.233]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 07\n",
            "\tTrain Loss: 0.018\n",
            "\t Val. Loss: 0.024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:04<00:00,  2.11s/it, loss=0.00499]\n",
            "100%|| 12/12 [00:23<00:00,  1.92s/it, loss=0.24]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 08\n",
            "\tTrain Loss: 0.017\n",
            "\t Val. Loss: 0.025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:03<00:00,  2.11s/it, loss=0.00133]\n",
            "100%|| 12/12 [00:22<00:00,  1.90s/it, loss=0.304]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 09\n",
            "\tTrain Loss: 0.015\n",
            "\t Val. Loss: 0.031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:03<00:00,  2.11s/it, loss=0.00627]\n",
            "100%|| 12/12 [00:23<00:00,  1.92s/it, loss=0.242]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10\n",
            "\tTrain Loss: 0.014\n",
            "\t Val. Loss: 0.025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:03<00:00,  2.11s/it, loss=0.0882]\n",
            "100%|| 12/12 [00:22<00:00,  1.90s/it, loss=0.327]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11\n",
            "\tTrain Loss: 0.014\n",
            "\t Val. Loss: 0.031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:03<00:00,  2.11s/it, loss=0.0014]\n",
            "100%|| 12/12 [00:23<00:00,  1.92s/it, loss=0.248]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12\n",
            "\tTrain Loss: 0.013\n",
            "\t Val. Loss: 0.031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:04<00:00,  2.11s/it, loss=0.000596]\n",
            "100%|| 12/12 [00:22<00:00,  1.91s/it, loss=0.339]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13\n",
            "\tTrain Loss: 0.013\n",
            "\t Val. Loss: 0.033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:03<00:00,  2.11s/it, loss=0.00413]\n",
            "100%|| 12/12 [00:22<00:00,  1.91s/it, loss=0.232]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14\n",
            "\tTrain Loss: 0.012\n",
            "\t Val. Loss: 0.026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:04<00:00,  2.11s/it, loss=0.000912]\n",
            "100%|| 12/12 [00:22<00:00,  1.91s/it, loss=0.225]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15\n",
            "\tTrain Loss: 0.011\n",
            "\t Val. Loss: 0.022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:03<00:00,  2.11s/it, loss=0.0347]\n",
            "100%|| 12/12 [00:23<00:00,  1.92s/it, loss=0.238]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16\n",
            "\tTrain Loss: 0.011\n",
            "\t Val. Loss: 0.030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:03<00:00,  2.11s/it, loss=0.00279]\n",
            "100%|| 12/12 [00:22<00:00,  1.91s/it, loss=0.23]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17\n",
            "\tTrain Loss: 0.011\n",
            "\t Val. Loss: 0.025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:03<00:00,  2.11s/it, loss=0.00158]\n",
            "100%|| 12/12 [00:23<00:00,  1.93s/it, loss=0.329]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18\n",
            "\tTrain Loss: 0.010\n",
            "\t Val. Loss: 0.047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:06<00:00,  2.12s/it, loss=0.000729]\n",
            "100%|| 12/12 [00:22<00:00,  1.91s/it, loss=0.224]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19\n",
            "\tTrain Loss: 0.011\n",
            "\t Val. Loss: 0.023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 343/343 [12:04<00:00,  2.11s/it, loss=0.000454]\n",
            "100%|| 12/12 [00:23<00:00,  1.93s/it, loss=0.256]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 20\n",
            "\tTrain Loss: 0.010\n",
            "\t Val. Loss: 0.025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_losses, valid_losses = train_model(seq2seq_test, train_loader, val_loader, CRITERION, N_EPOCHS)\n",
        "\n",
        "model_save_name = 'seq2seq.pt'\n",
        "path = f\"./gdrive/MyDrive/project-ML/full-length-{model_save_name}-{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\" \n",
        "torch.save(seq2seq_test.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7FXBMUn4PjA"
      },
      "outputs": [],
      "source": [
        "print(train_losses)\n",
        "print(valid_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf7O4iq7l8q6",
        "outputId": "d3d69c57-2864-4854-f351-3593880fd653"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load model\n",
        "seq2seq_test.load_state_dict(torch.load('./gdrive/MyDrive/project-ML/full-length-seq2seq.pt-2022-10-15-00-07-39'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP-e1gvP4O6x"
      },
      "outputs": [],
      "source": [
        "# plot train and validation loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses, label='train')\n",
        "plt.plot(valid_losses, label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kNYx_RYz-Hd"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "try:\n",
        "    del encoder_test\n",
        "    del decoder_test\n",
        "    del attention_test\n",
        "    del seq2seq_test\n",
        "except:\n",
        "    pass\n",
        "gc.collect()\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "2RzAHRR1Ec_H",
        "outputId": "3f2bda79-e51a-4395-8af5-f2f552032107"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb3e63c9710>]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAddUlEQVR4nO3de3Bc53nf8e+zF9wI7IoXkCIWYEhJlC1g6Vo2RVl1o2SsWqYmjhVPpJiS28gZz6gdV23aOk3lZkZxlZk27qSWPY2mY42txBfJsqPYHU5MW3aqTD1NZJqQ5IoEKYkULRHgDeBFBEBwASz26R97ACwgkFgSC57ds7/PjGbPnvOe3Qc74u+cfd+z5zV3R0REoisWdgEiIrK8FPQiIhGnoBcRiTgFvYhIxCnoRUQiLhF2AfOtWbPGN27cGHYZIiI15cUXXzzl7u0Lbau6oN+4cSO9vb1hlyEiUlPM7K2LbVPXjYhIxCnoRUQiTkEvIhJxCnoRkYhT0IuIRJyCXkQk4hT0IiIRF5mgPzc2yZf/9iB7B86FXYqISFWpuh9MXalYDB7729eJx2BLZzrsckREqkZZZ/Rmtt3MXjOzQ2b28ALbbzezl8wsb2b3LLA9ZWYDZvbnlSh6IW1NSTatWcG+o8PL9RYiIjVp0aA3szjwOHAX0A3cZ2bd85odAT4FPH2Rl/kT4KdXXmZ5spk0e4+q60ZEpFQ5Z/TbgEPuftjdJ4BngLtLG7j7m+7+ClCYv7OZvR9YB/y4AvVeUrYjxdG3L3D2/MRyv5WISM0oJ+gzQH/J84Fg3aLMLAb8d+APFmn3oJn1mlnv0NBQOS+9oGym2Dffd0zdNyIi05b7qpvPALvcfeBSjdz9CXff6u5b29sXvMtmWbIdxaBX942IyKxyrro5CnSVPO8M1pXjNuBXzewzQCvQYGaj7v6OAd1KSLck6VrVzL5jCnoRkWnlBP0eYLOZbaIY8DuA+8t5cXf/5PSymX0K2LpcIT8t25GmT2f0IiIzFu26cfc88BDwHHAA+K6795nZo2b2MQAzu8XMBoB7ga+YWd9yFn0p2UyaN0+PMZybDKsEEZGqUtYPptx9F7Br3rpHSpb3UOzSudRr/CXwl5dd4WWaGZA9Osxt169e7rcTEal6kbkFwrRsRwqAPvXTi4gAEQz61a2NdKSbdOWNiEggckEP0JNJs09BLyICRDTot2TSHD51nvPj+bBLEREJXSSDPptJ4Q77j+sXsiIi0Qz64Bey6r4REYlo0K9NNbG2rVEDsiIiRDTooXg9fZ/uTS8iEuGg70hxcHCECxNTYZciIhKq6AZ9Jk3B4cAJndWLSH2LdNADusGZiNS9yAb9+nQTq1Y0aA5ZEal7kQ16M9McsiIiRDjooTgg+/rJEcbzGpAVkfoV7aDPpMkXnNdPjIZdiohIaCId9FsymkNWRCTSQd+5splUU0JzyIpIXYt00E8PyOoSSxGpZ5EOeih23xw4McLkVCHsUkREQhH5oO/JpJnIFzh4UgOyIlKfIh/003PIqp9eROpVWUFvZtvN7DUzO2RmDy+w/XYze8nM8mZ2T8n695rZC2bWZ2avmNknKll8OTauXkFrY0L3pheRurVo0JtZHHgcuAvoBu4zs+55zY4AnwKenrd+DPhdd+8BtgNfMrNrllr05YjFjO6OlIJeROpWOWf024BD7n7Y3SeAZ4C7Sxu4+5vu/gpQmLf+dXc/GCwfAwaB9opUfhmyHWn2Hx8mrwFZEalD5QR9BugveT4QrLssZrYNaADeWGDbg2bWa2a9Q0NDl/vSi9rSmSI3WeDwqfMVf20RkWp3VQZjzWw98E3g99z9HafV7v6Eu291963t7ZU/4dccsiJSz8oJ+qNAV8nzzmBdWcwsBfwA+CN3/9nllVcZ17W30pyM61YIIlKXygn6PcBmM9tkZg3ADmBnOS8etP8+8A13f/bKy1yaeDAgqzlkRaQeLRr07p4HHgKeAw4A33X3PjN71Mw+BmBmt5jZAHAv8BUz6wt2/x3gduBTZvaL4L/3LstfsohsR4q+Y+coFDyMtxcRCU2inEbuvgvYNW/dIyXLeyh26czf71vAt5ZYY0VkM2m+/sJb/PL0ea5vbw27HBGRqybyv4ydNj2HrAZkRaTe1E3Q37C2lYZEjL5j6qcXkfpSN0GfjMe4aX2KvQM6oxeR+lI3QQ/FAdl9x87hrgFZEakf9RX0mTQjuTz9Zy6EXYqIyFVTV0GvOWRFpB7VVdBvXtdKMm66N72I1JW6CvrGRJwb17XpEksRqSt1FfRQ7L7Zd1QDsiJSP+ou6Hsyac6OTXLsXC7sUkREroq6C/rpOWR1Pb2I1Iu6C/qb1qeIx4w+DciKSJ2ou6BvSsbZvLZVA7IiUjfqLugBejrS7D06rAFZEakLdRn0WzIpTo2OMzgyHnYpIiLLri6DXrcsFpF6UpdBf9P6FGa6FYKI1Ie6DPoVjQmub29ln+aQFZE6UJdBD7NzyIqIRF39Bn0mzfFzOU6NakBWRKKtroMeNCArItFXVtCb2XYze83MDpnZwwtsv93MXjKzvJndM2/bA2Z2MPjvgUoVvlTdwa0QNIesiETdokFvZnHgceAuoBu4z8y65zU7AnwKeHrevquAPwZuBbYBf2xmK5de9tKlmpJsXN2ie96ISOSVc0a/DTjk7ofdfQJ4Bri7tIG7v+nurwCFeft+BPiJu59x97PAT4DtFai7IrKZtCYhEZHIKyfoM0B/yfOBYF05lrLvsstm0gycvcDbYxNhlyIismyqYjDWzB40s14z6x0aGrpq77tlZkBW/fQiEl3lBP1RoKvkeWewrhxl7evuT7j7Vnff2t7eXuZLL11PMCCr7hsRibJygn4PsNnMNplZA7AD2Fnm6z8H3GlmK4NB2DuDdVXhmpYGOlc261YIIhJpiwa9u+eBhygG9AHgu+7eZ2aPmtnHAMzsFjMbAO4FvmJmfcG+Z4A/oXiw2AM8GqyrGlsyafoU9CISYYlyGrn7LmDXvHWPlCzvodgts9C+TwJPLqHGZZXNpPnhvhMM5yZJNSXDLkdEpOKqYjA2TNP99H0akBWRiKr7oJ++FYJucCYiUVX3Qb+mtZH16Sbd80ZEIqvugx6m55BV0ItINCnoKV55c/jUec6P58MuRUSk4hT0QDaTwh0OHNeArIhEj4Ke2QFZdd+ISBQp6IF1qSba2xp1zxsRiSQFfUBzyIpIVCnoA9lMmoODo+Qmp8IuRUSkohT0gWwmzVTBNSArIpGjoA/MTBauOWRFJGIU9IGOdBMrW5Ls0xyyIhIxCvqAmWkOWRGJJAV9iWwmzesnRxjPa0BWRKJDQV8i25Fmcsp5/cRo2KWIiFSMgr7EzGTh6r4RkQhR0JfoWtVMW1NCt0IQkUhR0JcwM7IdmkNWRKJFQT/Pls40B06MMDlVCLsUEZGKUNDP09ORYiJf4OBJDciKSDQo6OfRgKyIRE1ZQW9m283sNTM7ZGYPL7C90cy+E2zfbWYbg/VJM/u6me01swNm9rnKll95G1evYEVDXP30IhIZiwa9mcWBx4G7gG7gPjPrntfs08BZd78BeAz4QrD+XqDR3bcA7wf+xfRBoFrFYqY5ZEUkUso5o98GHHL3w+4+ATwD3D2vzd3A14PlZ4E7zMwAB1aYWQJoBiaAqr9rWDaTZv/xYaYKHnYpIiJLVk7QZ4D+kucDwboF27h7HjgHrKYY+ueB48AR4M/c/cz8NzCzB82s18x6h4aGLvuPqLRsJkVussDhIQ3IikjtW+7B2G3AFNABbAI+a2bXzW/k7k+4+1Z339re3r7MJS1Oc8iKSJSUE/RHga6S553BugXbBN00aeA0cD/wI3efdPdB4O+BrUsterld395KUzKmOWRFJBLKCfo9wGYz22RmDcAOYOe8NjuBB4Lle4Dn3d0pdtd8CMDMVgAfAF6tROHLKR4zutendImliETCokEf9Lk/BDwHHAC+6+59ZvaomX0saPY1YLWZHQL+PTB9CebjQKuZ9VE8YPyFu79S6T9iOWQzafYfG6agAVkRqXGJchq5+y5g17x1j5Qs5yheSjl/v9GF1teCbCbNN154izdPn+e69tawyxERuWL6ZexFZDs0ICsi0aCgv4jN61ppSMTo02ThIlLjFPQXkYzHuOnaNvbpjF5EapyC/hJ6Mmn2HT1H8QIiEZHapKC/hGxHmuFcnv4zF8IuRUTkiinoL0G3LBaRKFDQX8KN17aSiJmuvBGRmqagv4TGRJwb12lAVkRqm4J+EVsyafqODWtAVkRqloJ+EdlMijPnJzh2Lhd2KSIiV0RBv4ie6QFZdd+ISI1S0C+ie32KeMw0h6yI1CwF/SKaknFuaG/VlTciUrMU9GXoyaTYp3veiEiNUtCXYUsmzdDIOIPDGpAVkdqjoC+D5pAVkVqmoC9D9/oUZmgOWRGpSQr6MqxoTHDdmhU6oxeRmqSgL1M2k6ZPNzcTkRqkoC/Tlkya4+dynBodD7sUEZHLoqAvU0+HfiErIrWprKA3s+1m9pqZHTKzhxfY3mhm3wm27zazjSXb3mNmL5hZn5ntNbOmypV/9fRkUgCaQ1ZEas6iQW9mceBx4C6gG7jPzLrnNfs0cNbdbwAeA74Q7JsAvgX8S3fvAX4dmKxY9VdRqinJxtUtOqMXkZpTzhn9NuCQux929wngGeDueW3uBr4eLD8L3GFmBtwJvOLu/w/A3U+7+1RlSr/6ejJpXXkjIjWnnKDPAP0lzweCdQu2cfc8cA5YDdwIuJk9Z2YvmdkfLvQGZvagmfWaWe/Q0NDl/g1XTbYjzcDZC7w9NhF2KSIiZVvuwdgE8E+ATwaPHzezO+Y3cvcn3H2ru29tb29f5pKu3PQcsuqnF5FaUk7QHwW6Sp53BusWbBP0y6eB0xTP/n/q7qfcfQzYBbxvqUWHpaejOCCr7hsRqSXlBP0eYLOZbTKzBmAHsHNem53AA8HyPcDzXpx77zlgi5m1BAeAXwP2V6b0q2/ligYy1zRrQFZEakpisQbunjezhyiGdhx40t37zOxRoNfddwJfA75pZoeAMxQPBrj7WTP7IsWDhQO73P0Hy/S3XBXTc8iKiNSKRYMewN13Uex2KV33SMlyDrj3Ivt+i+IllpGQzaT4Ud8JhnOTpJqSYZcjIrIo/TL2Mk3PIbtfZ/UiUiMU9Jcpq1shiEiNUdBfpva2Rq5NNSnoRaRmKOivQFZzyIpIDVHQX4FsJs0bQ6OcH8+HXYqIyKIU9Fcg25HGHQ4c11m9iFQ/Bf0VmJ4sXP30IlILFPRXYF2qkTWtjezVZOEiUgMU9FfAzMhmUppDVkRqgoL+Cm3JpDk4OEpusmZvry8idUJBf4V6OtJMFVwDsiJS9RT0VygbzCGr6+lFpNop6K9Q5ppmVrYk6dOVNyJS5RT0V6g4IKs5ZEWk+inol6CnI83rJ0cYz2tAVkSql4J+CbZk0kxOOQdPjoZdiojIRSnol2B6QFbdNyJSzRT0S7BhVQttTQndCkFEqpqCfgnMjGxHWpdYikhVU9AvUTaT4sDxYSanCmGXIiKyIAX9EmUzaSbyBQ4NakBWRKpTWUFvZtvN7DUzO2RmDy+wvdHMvhNs321mG+dt32Bmo2b2B5Upu3pM37JYA7IiUq0WDXoziwOPA3cB3cB9ZtY9r9mngbPufgPwGPCFedu/CPxw6eVWn02rV7CiIa5fyIpI1SrnjH4bcMjdD7v7BPAMcPe8NncDXw+WnwXuMDMDMLPfAn4J9FWm5OoSixndHZpDVkSqVzlBnwH6S54PBOsWbOPueeAcsNrMWoH/CPznS72BmT1oZr1m1js0NFRu7VUjm0mz/9gwUwUPuxQRkXdY7sHYzwOPufslRyrd/Ql33+ruW9vb25e5pMrLdqS5MDnF4SENyIpI9UmU0eYo0FXyvDNYt1CbATNLAGngNHArcI+Z/TfgGqBgZjl3//MlV15FZuaQPXaOzevaQq5GRGSucs7o9wCbzWyTmTUAO4Cd89rsBB4Ilu8BnveiX3X3je6+EfgS8F+iFvIA17evoCkZY++A+ulFpPosekbv7nkzewh4DogDT7p7n5k9CvS6+07ga8A3zewQcIbiwaBuJOIxblqfYp/mkBWRKlRO1w3uvgvYNW/dIyXLOeDeRV7j81dQX83IdqT5/stHKRScWMzCLkdEZIZ+GVshWzJpRsfzvHn6fNiliIjMoaCvkB7NISsiVUpBXyGb17bREI/pF7IiUnUU9BXSkIjx7vVtuueNiFQdBX0F9XSk2Xf0HO76hayIVA8FfQVtyaQZzuUZOHsh7FJERGYo6CtIc8iKSDVS0FfQjevaSMRMc8iKSFVR0FdQUzLOjevadImliFQVBX2FZTMpDciKSFVR0FdYNpPmzPkJXnjjtMJeRKqCgr7Cfv3GtbQ1Jbj/q7v56P/4vzy1+y1Gx/NhlyUidcyq7axz69at3tvbG3YZSzKSm+R//eIYT/3sLV49McKKhji/dXOG+2/dQE9HOuzyRCSCzOxFd9+64DYF/fJxd17uf5unfnaEv3nlGOP5Au/tuob7b93Ab76ng+aGeNglikhEKOirwLmxSf76pQGe/vkRDg2O0taU4Lff18knb92gWalEZMkU9FXE3fn5L8/w1O4j/GjfCSamCmzbuIr7b93A9uy1NCV1li8il09BX6VOj47z7IvFs/y3To+xsiXJvVu7uG/bBjatWRF2eSJSQxT0Va5QcP7hjdM8tfstfrL/JPmC88EbVvPJW3+FD3evIxnXxVEicmkK+hoyOJzju739fPvn/Rx9+wJrWhv5xC2d7LhlA12rWsIuT0SqlIK+Bk0VnJ++PsRTu4/w/KsnceDXbmzn/m0b+NC715LQWb6IlFDQ17hjb1/gmT39fGfPEU4Oj3Ntqokd27r4xC1drE83h12eiFSBJQe9mW0HvgzEga+6+5/O294IfAN4P3Aa+IS7v2lmHwb+FGgAJoD/4O7PX+q9FPQXl58q8L9fHeTp3Uf46cEhDLjjpnXcf+sGbt/cTjxmYZcoIiG5VNAnytg5DjwOfBgYAPaY2U5331/S7NPAWXe/wcx2AF8APgGcAn7T3Y+ZWRZ4Dsgs7c+pX4l4jI/0XMtHeq7lyOkxvr3nCH/V289P9p+kc2Uz923bwO9s7aK9rTHsUkWkiix6Rm9mtwGfd/ePBM8/B+Du/7WkzXNBmxfMLAGcANq95MXNzCie7a939/GLvZ/O6C/PRL7Aj/ef4OndR/iHN06TiBkf6bmW+2/dwG3XrSams3yRurCkM3qKZ+D9Jc8HgFsv1sbd82Z2DlhN8Yx+2m8DLy0U8mb2IPAgwIYNG8ooSaY1JGJ89D0dfPQ9HRweGuXbPz/CX704wA/2Hmd9uonr21vpWtVM58oWula10LWyuLymtYHisVdEoq6coF8yM+uh2J1z50Lb3f0J4AkontFfjZqi6Lr2Vv7oN7r57J3v4of7jvP8q0P0nxnjJ/tPcmp0Yk7b5mSczpXNM+HftaqFzpUtM+vSzcmQ/goRqbRygv4o0FXyvDNYt1CbgaDrJk2xmwYz6wS+D/yuu7+x5IplUU3JOB+/uZOP39w5s25sojhpef+ZseJ/08tnL7Dnl2cYmXcr5VRTIjgItNC1qnlmuTP4RqAbsonUjnKCfg+w2cw2UQz0HcD989rsBB4AXgDuAZ53dzeza4AfAA+7+99Xrmy5XC0NCW5c18aNF7mB2rmxSfrPTh8Exug/c4H+s2McHBzh714bZDxfmNN+TWtj8QAQHAg6V84eFDquadaveUWqyKJBH/S5P0Txipk48KS795nZo0Cvu+8EvgZ808wOAWcoHgwAHgJuAB4xs0eCdXe6+2Cl/xBZmnRLknRLmmzmnffLd3eGRsfpP3OBgemDQXAgeLn/LD/Ye5ypwmyPW8xgfbp5phtobVsjzck4zQ1xGpPx4nIyTnNDjKZEnKaG4vOmkm2NyRiNiZjGEUQqQD+YkiXLTxU4MZybCf+BOV1DY5wanZhzICiXGXMOAE3J2OzBoCFOY6L42FyyvinY1pSIFR9L9k/EDcMwg5gVHw2wkuXZ9cFjyfLF9jEzYvP3MZv3ekDwGi3BgU0HMamkpV51I3JJiXgsGMht4TZWL9hmcqrAhckpchNT5CaLyxcmp8hNP05MkctPcWGiMLM+NznFhZL1uZL2o+N5To1OzGsz9Y4upmqViBltTQlSzcniY1PpY/Id21ILtNVtMKRcCnq5KpLxGMl4jFTT8l7NUyg44/l5B5KJ4uPklOM4OBQcHMeLTykEC45TKBTXuTvFLyJz200v+8zy3H3mbpu7T6HgjE1MMZKbZDg3yUguz0guz/CFSd48NTazrpx5hlsa4nOCv60p+c4DR3NwkJh38GhrStKYiJGImb5Z1AEFvURKLGbF7pwavypoquCM5vIMBweE4Qv54OAQPAbPR4I2I7k8Z8cmOHJmjOELxX0mp8rrLkvGbeZAfFnLiRgN8eLBYno5GTcSQbuGoF2iZLn43IK2xS639rZG1qUaSTcnddBZJgp6kSoUj1kwQH5l34Dci99sLnaQGB2fZCJfYGLKmZwqkJ8qMDnlTEwVmMwXyBfmLk9OFZjIFxibyBe35QtMBvvkp2Zfp/haxX0vV0MixrpUI+vamliXamJtqpFrU7PL64Ll1kbF1uXSJyYSQWY2MxC9NoQpid195gAxWXIQmMw7k4XZ5bGJPEOj45wcHmdwOMfJ4Rwnh8c5cGKY//P6+IJdWCsa4u8I/7Vts8vrgvW1Ni3n9Ge2HJcmK+hFpOLMbKaLZylGx/MMDuc4MZxjcHh85kBwciTH4HCOl4+8zYnhHBMLDMKnm5Mzob+2bfYAsC7VyNrgoNDe2khD4p01ujuTU04uXxzfGZ8sMJ4vXkhQvCggeJyzrngxwPjkFLn87LrZtoW5baa35Wf3vbnrGr73mQ8u6TNbiIJeRKpWa2OC1vZWrmtvvWgbd2f4Qp4TM98IcgyOjM8snxwe543BUwyOjJNf4DLf1SsaSDUn3xHQV3BF8IzpS4GbErOXBTcmYjQm46SbkzS1NQbfuGIz37waEzG6Vi7PLHIKehGpaWaz4xnvuvbi/VSFgnNmbIIT53IMjgTfDIIDwUhucjZ4E/E5IdwYhHAxuGeDuTTMG4P9qvWHfgp6EakLsZixprWRNa2NFG/HVT/0iwsRkYhT0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIk5BLyIScVU3w5SZDQFvLeEl1gCnKlROrdNnMZc+j7n0ecyKwmfxK+7evtCGqgv6pTKz3otNp1Vv9FnMpc9jLn0es6L+WajrRkQk4hT0IiIRF8WgfyLsAqqIPou59HnMpc9jVqQ/i8j10YuIyFxRPKMXEZESCnoRkYiLTNCb2XYze83MDpnZw2HXEyYz6zKzvzOz/WbWZ2a/H3ZNYTOzuJm9bGZ/E3YtYTOza8zsWTN71cwOmNltYdcUJjP7d8G/k31m9m0zawq7pkqLRNCbWRx4HLgL6AbuM7PucKsKVR74rLt3Ax8A/lWdfx4Avw8cCLuIKvFl4Efu/m7gH1HHn4uZZYB/A2x19ywQB3aEW1XlRSLogW3AIXc/7O4TwDPA3SHXFBp3P+7uLwXLIxT/IWfCrSo8ZtYJ/Abw1bBrCZuZpYHbga8BuPuEu78dblWhSwDNZpYAWoBjIddTcVEJ+gzQX/J8gDoOtlJmthG4GdgdbiWh+hLwh0Ah7EKqwCZgCPiLoCvrq2a2IuyiwuLuR4E/A44Ax4Fz7v7jcKuqvKgEvSzAzFqBvwb+rbsPh11PGMzso8Cgu78Ydi1VIgG8D/if7n4zcB6o2zEtM1tJ8dv/JqADWGFm/yzcqiovKkF/FOgqed4ZrKtbZpakGPJPufv3wq4nRB8EPmZmb1Ls0vuQmX0r3JJCNQAMuPv0N7xnKQZ/vfqnwC/dfcjdJ4HvAf845JoqLipBvwfYbGabzKyB4mDKzpBrCo2ZGcU+2APu/sWw6wmTu3/O3TvdfSPF/y+ed/fInbGVy91PAP1m9q5g1R3A/hBLCtsR4ANm1hL8u7mDCA5OJ8IuoBLcPW9mDwHPURw1f9Ld+0IuK0wfBP45sNfMfhGs+0/uvivEmqR6/GvgqeCk6DDweyHXExp3321mzwIvUbxa7WUieDsE3QJBRCTiotJ1IyIiF6GgFxGJOAW9iEjEKehFRCJOQS8iEnEKehGRiFPQi4hE3P8H+q8hHBvsIf8AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsr04bttAgO1"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z84UCWWEDhQ8",
        "outputId": "6cc70cf1-1245-4913-d3b9-dde97df0249c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:01,  1.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.010146934539079666\n",
            "0.010146934539079666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def test(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    with torch.no_grad():\n",
        "        for i, batch in tqdm.tqdm(enumerate(iterator)):\n",
        "            output = model(batch, inference=True)\n",
        "            real_target = batch[2][:, :, 0].to(device)\n",
        "            loss = criterion(output, real_target)\n",
        "            epoch_loss += loss.item()\n",
        "            tqdm.tqdm.write(f'loss: {loss.item()}')\n",
        "    return epoch_loss / len(iterator) # loss per batch\n",
        "\n",
        "test_loss = test(seq2seq_test, test_loader, CRITERION)\n",
        "print(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_RRE-sEGwaL",
        "outputId": "4ed869d7-81ac-45cb-c286-884bdf75697f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1024, 30]) torch.Size([370, 60, 8]) torch.Size([370, 60, 1]) torch.Size([370, 30])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 0.010146934539079666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# transform back to original scale\n",
        "def inverse_transform(data, scaler):\n",
        "    return scaler.inverse_transform(data)\n",
        "\n",
        "# predict\n",
        "def predict(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    outputs = torch.empty(BATCH_SIZE, OUT_SEQ_LEN).to(device) # y hat\n",
        "    batches_features = torch.empty(next(iter(iterator))[0].shape).to(device)\n",
        "    batches_user = torch.empty(next(iter(iterator))[1].shape).to(device)\n",
        "    batches_y = torch.empty(next(iter(iterator))[2].shape).squeeze(2).to(device)\n",
        "    print(outputs.shape, batches_features.shape, batches_user.shape, batches_y.shape)\n",
        "    with torch.no_grad():\n",
        "        for i, batch in tqdm.tqdm(enumerate(iterator)):\n",
        "            output = model(batch, inference=True)\n",
        "            #real_target = batch[2][:, :, 0].to(device)\n",
        "            loss = criterion(output, batch[2][:, :, 0].to(device))\n",
        "            epoch_loss += loss.item()\n",
        "            tqdm.tqdm.write(f'loss: {loss.item()}')\n",
        "            # inverse transform\n",
        "            #output = inverse_transform(output, scaler)\n",
        "            #real_target = inverse_transform(real_target, scaler)\n",
        "            outputs = torch.cat((outputs, output), dim = 0)\n",
        "            batches_features = torch.cat((batches_features, batch[0].to(device)), dim = 0)\n",
        "            batches_user = torch.cat((batches_user, batch[1].to(device)), dim = 0)\n",
        "            batches_y = torch.cat((batches_y, batch[2][:, :, 0].to(device)), dim = 0)\n",
        "            \n",
        "        return outputs, (batches_features, batches_user, batches_y)\n",
        "\n",
        "y_hat, test_batch = predict(seq2seq_test, test_loader, CRITERION)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nDSZDjDw4Jt"
      },
      "outputs": [],
      "source": [
        "y_hat = y_hat[BATCH_SIZE:,:]\n",
        "test_batch = [_[370:, :, :] if len(_.shape) > 2 else _[370:, :] for _ in test_batch]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10YcX4ayw7LM",
        "outputId": "e23e6eb8-ba6e-4496-89bc-a9abed0092d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([370, 30])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_hat.shape\n",
        "test_batch[0].shape\n",
        "test_batch[1].shape\n",
        "test_batch[2].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44hfVG9CNCMI"
      },
      "outputs": [],
      "source": [
        "def construct_df(output, batch):\n",
        "    # batch[0] = time series features (batch_size, in_seq_len, feature_size)\n",
        "    # batch[1] = static user flag (batch_size, in_seq_len, 1)\n",
        "    # batch[2] = target (batch_size, out_seq_len, 1)\n",
        "\n",
        "    # output = (batch_size, out_seq_len)\n",
        "    if output.shape[1] != batch[1].shape[1]:\n",
        "        users = batch[1][:, :output.shape[1], 0].cpu().numpy()\n",
        "    else:\n",
        "        users = batch[1][:, :, 0].cpu().numpy()\n",
        "    users = users.reshape(-1)\n",
        "\n",
        "    y_hat = output.cpu().numpy()\n",
        "    y_hat = y_hat.reshape(-1)\n",
        "\n",
        "    y = batch[2].cpu().numpy()\n",
        "    y = y.reshape(-1)\n",
        "\n",
        "    \n",
        "    day = list(range(1, (output.shape[1] + 1))) * batch[1].shape[0]\n",
        "    #print(len(day), print())\n",
        "    df = pd.DataFrame({'user': users, 'day': day, 'y_hat': y_hat, 'y': y})\n",
        "\n",
        "    return df\n",
        "\n",
        "df_pred = construct_df(y_hat, test_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TJ4oUoOAeCX8",
        "outputId": "fee841f1-5f23-4d35-843a-526481bd19d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-87fcf28e-84a2-4a10-83db-874e9beb4181\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>day</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.173536</td>\n",
              "      <td>-0.178633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.173553</td>\n",
              "      <td>-0.178496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.181614</td>\n",
              "      <td>-0.178425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.183766</td>\n",
              "      <td>-0.178719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.184071</td>\n",
              "      <td>-0.178591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11095</th>\n",
              "      <td>370</td>\n",
              "      <td>26</td>\n",
              "      <td>5.812806</td>\n",
              "      <td>2.931079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11096</th>\n",
              "      <td>370</td>\n",
              "      <td>27</td>\n",
              "      <td>5.820715</td>\n",
              "      <td>3.380300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11097</th>\n",
              "      <td>370</td>\n",
              "      <td>28</td>\n",
              "      <td>5.827989</td>\n",
              "      <td>4.472764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11098</th>\n",
              "      <td>370</td>\n",
              "      <td>29</td>\n",
              "      <td>5.835185</td>\n",
              "      <td>4.620553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>370</td>\n",
              "      <td>30</td>\n",
              "      <td>5.842201</td>\n",
              "      <td>5.123478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11100 rows  4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87fcf28e-84a2-4a10-83db-874e9beb4181')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87fcf28e-84a2-4a10-83db-874e9beb4181 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87fcf28e-84a2-4a10-83db-874e9beb4181');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       user  day     y_hat         y\n",
              "0         1    1 -0.173536 -0.178633\n",
              "1         1    2 -0.173553 -0.178496\n",
              "2         1    3 -0.181614 -0.178425\n",
              "3         1    4 -0.183766 -0.178719\n",
              "4         1    5 -0.184071 -0.178591\n",
              "...     ...  ...       ...       ...\n",
              "11095   370   26  5.812806  2.931079\n",
              "11096   370   27  5.820715  3.380300\n",
              "11097   370   28  5.827989  4.472764\n",
              "11098   370   29  5.835185  4.620553\n",
              "11099   370   30  5.842201  5.123478\n",
              "\n",
              "[11100 rows x 4 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pred['user'] = df_pred['user'].astype(int)\n",
        "df_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MfjJM7ZjeAFF",
        "outputId": "96580942-710b-4afd-d1cf-b166d3c0858c"
      },
      "outputs": [],
      "source": [
        "for user in df_pred['user'].unique():\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    df_user = df_pred[df_pred['user'] == user]\n",
        "    ax.plot(df_user['day'], df_user['y_hat'], label=f'user {user}', alpha=0.5, linestyle = '--')\n",
        "    ax.plot(df_user['day'], df_user['y'], label=f'user {user}')\n",
        "    #plt.legend()\n",
        "    plt.title(f\"user: {user}\")\n",
        "    plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzo3CeaQ2avK"
      },
      "outputs": [],
      "source": [
        "df_pred['y'] = target_scaler.inverse_transform(df_pred['y'].values.reshape(-1,1))\n",
        "df_pred['y_hat'] = target_scaler.inverse_transform(df_pred['y_hat'].values.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kfOU799FX5ei",
        "outputId": "582aaf1e-03fe-4cbc-a2e3-6abaaa7a2e3d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9d39caf0-9862-490b-b41e-37018f865610\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>day</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.555028e+03</td>\n",
              "      <td>1.903563e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.550559e+03</td>\n",
              "      <td>2.271571e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-6.077218e+02</td>\n",
              "      <td>2.461922e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1.183804e+03</td>\n",
              "      <td>1.675125e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-1.265519e+03</td>\n",
              "      <td>2.017782e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11095</th>\n",
              "      <td>370</td>\n",
              "      <td>26</td>\n",
              "      <td>1.604284e+06</td>\n",
              "      <td>8.327568e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11096</th>\n",
              "      <td>370</td>\n",
              "      <td>27</td>\n",
              "      <td>1.606402e+06</td>\n",
              "      <td>9.530271e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11097</th>\n",
              "      <td>370</td>\n",
              "      <td>28</td>\n",
              "      <td>1.608349e+06</td>\n",
              "      <td>1.245514e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11098</th>\n",
              "      <td>370</td>\n",
              "      <td>29</td>\n",
              "      <td>1.610276e+06</td>\n",
              "      <td>1.285081e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11099</th>\n",
              "      <td>370</td>\n",
              "      <td>30</td>\n",
              "      <td>1.612154e+06</td>\n",
              "      <td>1.419730e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11100 rows  4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d39caf0-9862-490b-b41e-37018f865610')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d39caf0-9862-490b-b41e-37018f865610 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d39caf0-9862-490b-b41e-37018f865610');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       user  day         y_hat             y\n",
              "0         1    1  1.555028e+03  1.903563e+02\n",
              "1         1    2  1.550559e+03  2.271571e+02\n",
              "2         1    3 -6.077218e+02  2.461922e+02\n",
              "3         1    4 -1.183804e+03  1.675125e+02\n",
              "4         1    5 -1.265519e+03  2.017782e+02\n",
              "...     ...  ...           ...           ...\n",
              "11095   370   26  1.604284e+06  8.327568e+05\n",
              "11096   370   27  1.606402e+06  9.530271e+05\n",
              "11097   370   28  1.608349e+06  1.245514e+06\n",
              "11098   370   29  1.610276e+06  1.285081e+06\n",
              "11099   370   30  1.612154e+06  1.419730e+06\n",
              "\n",
              "[11100 rows x 4 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_pred"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.2 ('venv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "604fdf8ab36a5e651bb574a7b75ac275368dad065bbd59a228db0a9954e1d4d2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
